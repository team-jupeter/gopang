# GOPANG EXAONE Fine-tuning ê²°ê³¼ ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2026-01-24  
**í”„ë¡œì íŠ¸**: GOPANG AI ì‹œìŠ¤í…œ  
**ì‘ì„±ì**: Day 21 ì„¸ì…˜  

---

## 1. ê°œìš”

### 1.1 ëª©í‘œ
- EXAONE 7.8B ëª¨ë¸ì„ GOPANG ì „ìš© ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ Fine-tuning
- EC2 ì„œë²„ì— ë°°í¬í•˜ì—¬ ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì ìš©

### 1.2 ê²°ê³¼ ìš”ì•½

| í•­ëª© | ê²°ê³¼ |
|------|------|
| Fine-tuning | âœ… ì„±ê³µ |
| ëª¨ë¸ ë³€í™˜ (GGUF) | âœ… ì„±ê³µ |
| EC2 ë°°í¬ | âœ… ì„±ê³µ |
| GOPANG í˜•ì‹ ì‘ë‹µ | âš ï¸ ê¸´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í•„ìš” |
| ì‘ë‹µ ì†ë„ | âš ï¸ CPU ê¸°ë°˜ìœ¼ë¡œ ëŠë¦¼ (1-2ë¶„) |

---

## 2. Fine-tuning ê³¼ì •

### 2.1 í™˜ê²½
- **í”Œë«í¼**: Google Colab Pro
- **GPU**: A100 80GB
- **í•™ìŠµ ì‹œê°„**: ì•½ 4ì‹œê°„ 32ë¶„

### 2.2 ë°ì´í„°ì…‹

| íŒŒì¼ | ìƒ˜í”Œ ìˆ˜ | ìœ„ì¹˜ |
|------|---------|------|
| train.jsonl | 14,014 | Google Drive |
| validation.jsonl | 779 | Google Drive |

### 2.3 í•™ìŠµ ì„¤ì •
```python
# LoRA ì„¤ì •
LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_dropout=0.05,
    task_type="CAUSAL_LM"
)

# í•™ìŠµ ì„¤ì • (trl 0.27.0)
SFTConfig(
    num_train_epochs=3,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,
    learning_rate=2e-5,
    max_length=2048,  # trl 0.27.0: max_seq_length â†’ max_length
    bf16=True
)

# SFTTrainer (trl 0.27.0)
SFTTrainer(
    processing_class=tokenizer,  # tokenizer â†’ processing_class
)
```

### 2.4 í•™ìŠµ ê²°ê³¼

| ì§€í‘œ | ì‹œì‘ | ìµœì¢… | ê°œì„  |
|------|------|------|------|
| **Loss** | 3.82 | 0.29 | â¬‡ï¸ 92% ê°ì†Œ |
| **Accuracy** | 44% | 93.4% | â¬†ï¸ +49% |
| **Eval Loss** | 3.57 | 0.30 | â¬‡ï¸ 92% ê°ì†Œ |

### 2.5 trl 0.27.0 API ë³€ê²½ì‚¬í•­ (ì¤‘ìš”!)

| ì´ì „ ë²„ì „ | trl 0.27.0 |
|----------|------------|
| max_seq_length | max_length |
| tokenizer= | processing_class= |

---

## 3. ëª¨ë¸ ë³€í™˜

### 3.1 EXAONE ì–‘ìí™” ë¬¸ì œ í•´ê²°

**ë¬¸ì œ**: `key not found: exaone.attention.layer_norm_rms_epsilon`

**í•´ê²°**: convert_hf_to_gguf.py ìˆ˜ì •
```python
# ExaoneModel í´ë˜ìŠ¤ì— ì¶”ê°€
self.gguf_writer.add_layer_norm_rms_eps(hparams["layer_norm_epsilon"])
```

### 3.2 ìµœì¢… íŒŒì¼

| íŒŒì¼ | í¬ê¸° | ìš©ë„ |
|------|------|------|
| gopang-exaone-finetuned-v1/ | 18MB | LoRA ì–´ëŒ‘í„° |
| gopang-exaone-finetuned-f16-v2.gguf | 15GB | F16 ë°±ì—… |
| **gopang-exaone-finetuned-Q4_K_M.gguf** | **4.5GB** | **EC2 ë°°í¬ìš©** |

---

## 4. ì‘ë‹µ ì†ë„ ë¶„ì„

### 4.1 í˜„ì¬ ì„±ëŠ¥ (CPU, t3.large)

| í”„ë¡¬í”„íŠ¸ í¬ê¸° | ì‘ë‹µ í† í° | ì†Œìš” ì‹œê°„ |
|--------------|----------|----------|
| 27 í† í° | 46 í† í° | ~35ì´ˆ |
| 53 í† í° | 100 í† í° | ~65ì´ˆ |
| 185 í† í° | 136 í† í° | ~130ì´ˆ |

### 4.2 ì†ë„ ê°œì„  ë°©ì•ˆ

| ì˜µì…˜ | ì˜ˆìƒ ì†ë„ | ë¹„ìš© |
|------|----------|------|
| g4dn.xlarge (T4 GPU) | 3~5ì´ˆ | $0.526/ì‹œê°„ |
| g5.xlarge (A10G GPU) | 2~3ì´ˆ | $1.006/ì‹œê°„ |
| EXAONE 2.4B | 20~30ì´ˆ | í˜„ì¬ ë¹„ìš© ìœ ì§€ |
| DeepSeek API | 1~3ì´ˆ | í† í°ë‹¹ ê³¼ê¸ˆ |

---

## 5. GOPANG í˜•ì‹ ì‘ë‹µ ì¡°ê±´

ê¸´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í•„ìš”:
```
ë‹¹ì‹ ì€ GOPANG ì¤‘ê°œ AIì…ë‹ˆë‹¤.
í˜¸ì¶œ ê°€ëŠ¥: ê²½ì°°ì²­_AI, ë²•ì›_AI, ì£¼ë¯¼ì„¼í„°_AI...
ì‘ë‹µ í˜•ì‹:
[ì‚¬ìš©ììœ„ì¹˜: ì§€ì—­]
[Vault ì ‘ê·¼] ì „ë¬¸ê¸°ê´€_AI í˜¸ì¶œ
ğŸ¤– ì „ë¬¸ê¸°ê´€_AI: [ì—…ë¬´ ì²˜ë¦¬ ê²°ê³¼]
```

---

## 6. íŒŒì¼ ìœ„ì¹˜

### Google Drive
```
gopang_exaone_dataset_v4/  (í•™ìŠµ ë°ì´í„°)
gopang-exaone-finetuned-v1/  (LoRA)
gopang-exaone-merged/  (ë³‘í•© ëª¨ë¸)
gopang-exaone-finetuned-Q4_K_M.gguf  (ì–‘ìí™”)
```

### EC2
```
/gopang/ai-engine/models/gopang-exaone-finetuned-Q4_K_M.gguf
```

---

## 7. ì°¸ê³  ëª…ë ¹ì–´
```bash
# EC2 ì ‘ì†
ssh -i "gopang-dev-key.pem" -p 2222 ubuntu@13.222.8.230

# ì„œë¹„ìŠ¤ ê´€ë¦¬
sudo systemctl status llama-server gopang-ai gopang-backend
sudo systemctl restart llama-server

# í…ŒìŠ¤íŠ¸
curl http://localhost:8000/health
```

---

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ìµœì¢… ìˆ˜ì •**: 2026-01-24
